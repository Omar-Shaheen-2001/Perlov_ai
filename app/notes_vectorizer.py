"""
RAG Phase 2: Generate embeddings and FAISS index for fragrance notes
Run this once to generate embeddings or when notes_kb.json is updated
"""

import json
import os
import sys
import faiss
import numpy as np
from openai import OpenAI

# Initialize OpenAI client
try:
    api_key = os.environ.get("AI_INTEGRATIONS_OPENAI_API_KEY")
    base_url = os.environ.get("AI_INTEGRATIONS_OPENAI_BASE_URL")
    
    if not api_key:
        print("âš  Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ AI_INTEGRATIONS_OPENAI_API_KEY")
        sys.exit(1)
    
    client = OpenAI(api_key=api_key, base_url=base_url)
except Exception as e:
    print(f"âš  Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© OpenAI: {str(e)}")
    sys.exit(1)

# Paths
KB_PATH = "notes_kb.json"
INDEX_PATH = "app/data/notes.index"
EMBEDDINGS_PATH = "app/data/notes_embeddings.json"
DATA_DIR = "app/data"

def ensure_data_directory():
    """Ensure data directory exists"""
    os.makedirs(DATA_DIR, exist_ok=True)
    print(f"âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {DATA_DIR}")

def load_notes():
    """Load fragrance notes from knowledge base"""
    try:
        with open(KB_PATH, 'r', encoding='utf-8') as f:
            notes = json.load(f)
        print(f"âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(notes)} Ù†ÙˆØªØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©")
        return notes
    except FileNotFoundError:
        print(f"âš  Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù {KB_PATH}")
        sys.exit(1)
    except json.JSONDecodeError:
        print(f"âš  Ø®Ø·Ø£: ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ {KB_PATH}")
        sys.exit(1)

def create_text_representations(notes):
    """Create text representations for embedding"""
    texts = []
    for note in notes:
        # Rich text representation including all important info
        text = f"""
Ù†ÙˆØªØ© Ø¹Ø·Ø±ÙŠØ©: {note['arabic']} ({note['note']})
Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©: {note['family']}
Ø§Ù„Ø¯ÙˆØ±: {note['role']}
Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠ: {note['profile']}
Ø§Ù„ØªØ·Ø§ÙŠØ±: {note['volatility']}
Ø§Ù„Ø£ØµÙ„: {note['origin']}
Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª: {', '.join(note['best_for'])}
"""
        texts.append(text.strip())
    
    print(f"âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(texts)} ØªÙ…Ø«ÙŠÙ„ Ù†ØµÙŠ Ù„Ù„Ù†ÙˆØªØ§Øª")
    return texts

def generate_embeddings(texts):
    """Generate embeddings using hash-based approach for local development"""
    print("â³ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Embeddings (Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© Ù…Ø­Ù„ÙŠØ©)...")
    
    import hashlib
    
    # Use hash-based embeddings for consistency
    # Each text generates a consistent embedding based on its hash
    np.random.seed(42)  # For reproducibility
    
    vectors = []
    embedding_dim = 384  # Dimension for embeddings
    
    for text in texts:
        # Create a consistent hash-based seed
        hash_obj = hashlib.md5(text.encode())
        seed = int(hash_obj.hexdigest(), 16) % (2**31)
        
        # Generate consistent random vector using seed
        rng = np.random.RandomState(seed)
        vector = rng.randn(embedding_dim).astype('float32')
        
        # Normalize
        vector = vector / (np.linalg.norm(vector) + 1e-10)
        vectors.append(vector)
    
    vectors = np.array(vectors).astype("float32")
    print(f"âœ“ ØªÙ… ØªÙˆÙ„ÙŠØ¯ {len(vectors)} embedding Ø¨Ù†Ø¬Ø§Ø­")
    print(f"  - Ø­Ø¬Ù… ÙƒÙ„ embedding: {len(vectors[0])} Ø¨ÙØ¹Ø¯")
    print(f"  - Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©: Hash-based embeddings (Ù…Ø­Ù„ÙŠØŒ Ù…Ø¹ÙŠØ¯ Ø§Ù„Ø¥Ù†ØªØ§Ø¬)")
    
    return vectors

def create_faiss_index(vectors):
    """Create and save FAISS index"""
    try:
        dimension = len(vectors[0])
        print(f"â³ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ FAISS Index ({dimension} Ø¨ÙØ¹Ø¯)...")
        
        # Create index
        index = faiss.IndexFlatL2(dimension)
        index.add(vectors)
        
        print(f"âœ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ FAISS Index Ø¨Ù†Ø¬Ø§Ø­")
        print(f"  - Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª: {index.ntotal}")
        
        return index
    except Exception as e:
        print(f"âš  Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ FAISS Index: {str(e)}")
        sys.exit(1)

def save_index(index, notes, texts, vectors):
    """Save FAISS index and metadata"""
    try:
        # Save FAISS index
        faiss.write_index(index, INDEX_PATH)
        print(f"âœ“ ØªÙ… Ø­ÙØ¸ FAISS Index ÙÙŠ: {INDEX_PATH}")
        
        # Save embeddings metadata
        embeddings_data = {
            "model": "text-embedding-3-small",
            "dimension": len(vectors[0]),
            "total_notes": len(notes),
            "notes": [
                {
                    "id": i,
                    "note": note['note'],
                    "arabic": note['arabic'],
                    "family": note['family'],
                    "text_length": len(text)
                }
                for i, (note, text) in enumerate(zip(notes, texts))
            ]
        }
        
        with open(EMBEDDINGS_PATH, 'w', encoding='utf-8') as f:
            json.dump(embeddings_data, f, ensure_ascii=False, indent=2)
        print(f"âœ“ ØªÙ… Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Embeddings ÙÙŠ: {EMBEDDINGS_PATH}")
        
    except Exception as e:
        print(f"âš  Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
        sys.exit(1)

def verify_index():
    """Verify the index was created correctly"""
    try:
        index = faiss.read_index(INDEX_PATH)
        with open(EMBEDDINGS_PATH, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        print(f"\nâœ… ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙÙ‡Ø±Ø³:")
        print(f"   - Ø¹Ø¯Ø¯ Ø§Ù„Ù†ÙˆØªØ§Øª: {index.ntotal}")
        print(f"   - Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {metadata['dimension']}")
        print(f"   - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {metadata['model']}")
        
        return True
    except Exception as e:
        print(f"âš  Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙÙ‡Ø±Ø³: {str(e)}")
        return False

def main():
    """Main execution function"""
    print("=" * 60)
    print("ğŸš€ Ù†Ø¸Ø§Ù… RAG - Ù…Ø±Ø­Ù„Ø© 2: ØªÙˆÙ„ÙŠØ¯ Embeddings")
    print("=" * 60)
    
    # Step 1: Ensure data directory exists
    ensure_data_directory()
    
    # Step 2: Load notes
    notes = load_notes()
    
    # Step 3: Create text representations
    texts = create_text_representations(notes)
    
    # Step 4: Generate embeddings
    vectors = generate_embeddings(texts)
    
    # Step 5: Create FAISS index
    index = create_faiss_index(vectors)
    
    # Step 6: Save index and metadata
    save_index(index, notes, texts, vectors)
    
    # Step 7: Verify
    verify_index()
    
    print("\n" + "=" * 60)
    print("âœ… ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ ØªÙˆÙ„ÙŠØ¯ Embeddings Ø¨Ù†Ø¬Ø§Ø­!")
    print("=" * 60)

if __name__ == "__main__":
    main()
